{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s-SbSGeiiHWW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, LSTM, RepeatVector\n",
        "\n",
        "\n",
        "# Load data\n",
        "data = pd.read_excel('D:\\\\finalyear\\\\sine-wave-denoise\\\\Dataset\\\\ex1.xlsx')\n",
        "original_amplitude = data['Amplitude'].values\n",
        "noised_amplitude = data['Amplitude_noise'].values\n",
        "\n",
        "# Reshape and scale data\n",
        "original_amplitude = original_amplitude.reshape(-1, 1)\n",
        "noised_amplitude = noised_amplitude.reshape(-1, 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "original_amplitude = scaler.fit_transform(original_amplitude)\n",
        "noised_amplitude = scaler.transform(noised_amplitude)\n",
        "\n",
        "# Windowing function\n",
        "window_size = 4500\n",
        "\n",
        "def create_windows(data, window_size):\n",
        "    windows = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        windows.append(data[i:i + window_size])\n",
        "    return np.array(windows)\n",
        "\n",
        "X = create_windows(noised_amplitude, window_size)\n",
        "y = create_windows(original_amplitude, window_size)\n",
        "\n",
        "# Reshape for training\n",
        "X_train = X.reshape(-1, window_size, 1)\n",
        "y_train = y.reshape(-1, window_size, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8zgduNziMZj",
        "outputId": "3ad4a175-9ea0-4cc3-b5e1-e2f590407e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 198s 1s/step - loss: 0.3618 - val_loss: 0.3390\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 3s 393ms/step - loss: 0.2834 - val_loss: 0.2061\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 3s 406ms/step - loss: 0.1532 - val_loss: 0.0860\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 3s 393ms/step - loss: 0.0557 - val_loss: 0.0324\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 3s 382ms/step - loss: 0.0373 - val_loss: 0.0388\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 3s 399ms/step - loss: 0.0325 - val_loss: 0.0264\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 3s 394ms/step - loss: 0.0270 - val_loss: 0.0254\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 3s 389ms/step - loss: 0.0224 - val_loss: 0.0192\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 3s 390ms/step - loss: 0.0181 - val_loss: 0.0151\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 3s 404ms/step - loss: 0.0138 - val_loss: 0.0117\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 3s 417ms/step - loss: 0.0103 - val_loss: 0.0080\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 3s 394ms/step - loss: 0.0071 - val_loss: 0.0052\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 3s 396ms/step - loss: 0.0045 - val_loss: 0.0032\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 3s 387ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 3s 406ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 3s 400ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 3s 433ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 3s 413ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 3s 424ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 3s 379ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "16/16 [==============================] - 4s 95ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Conv1D Autoencoder Model\n",
        "input_signal = Input(shape=(window_size, 1))\n",
        "x = Conv1D(16, 3, activation='relu', padding='same')(input_signal)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 3, activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling1D(2, padding='same')(x)\n",
        "\n",
        "x = Conv1D(8, 3, activation='relu', padding='same')(encoded)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "decoded = Conv1D(1, 3, activation='relu', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_signal, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train Conv1D Autoencoder\n",
        "autoencoder.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
        "denoised_signal = autoencoder.predict(X_train)\n",
        "denoised_signal = scaler.inverse_transform(denoised_signal.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZycHUhyigEk",
        "outputId": "546f8223-9b10-4a4f-90ed-7681141d2222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 320s 43s/step - loss: 0.3561 - val_loss: 0.3342\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 258s 37s/step - loss: 0.2945 - val_loss: 0.2085\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 261s 38s/step - loss: 0.1790 - val_loss: 0.1311\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 244s 34s/step - loss: 0.1487 - val_loss: 0.1359\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 215s 31s/step - loss: 0.1387 - val_loss: 0.1313\n",
            "Epoch 6/20\n",
            "2/7 [=======>......................] - ETA: 3:16 - loss: 0.1369"
          ]
        }
      ],
      "source": [
        "\n",
        "# LSTM Autoencoder Model\n",
        "input_signal_lstm = Input(shape=(window_size, 1))\n",
        "encoded_lstm = LSTM(64, activation='relu', return_sequences=True)(input_signal_lstm)\n",
        "encoded_lstm = LSTM(32, activation='relu', return_sequences=False)(encoded_lstm)\n",
        "\n",
        "decoded_lstm = RepeatVector(window_size)(encoded_lstm)\n",
        "decoded_lstm = LSTM(32, activation='relu', return_sequences=True)(decoded_lstm)\n",
        "decoded_lstm = LSTM(64, activation='relu', return_sequences=True)(decoded_lstm)\n",
        "decoded_lstm = Conv1D(1, 3, activation='relu', padding='same')(decoded_lstm)\n",
        "\n",
        "lstm_autoencoder = Model(input_signal_lstm, decoded_lstm)\n",
        "lstm_autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train LSTM Autoencoder\n",
        "lstm_autoencoder.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
        "denoised_signal_lstm = lstm_autoencoder.predict(X_train)\n",
        "denoised_signal_lstm = scaler.inverse_transform(denoised_signal_lstm.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6IqOfWOijKw",
        "outputId": "f857b157-26a3-4f23-f7c2-43609ba4eaf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 107s 668ms/step - loss: 0.3538 - val_loss: 0.2962\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.2352 - val_loss: 0.1546\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 3s 455ms/step - loss: 0.1085 - val_loss: 0.0534\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 4s 590ms/step - loss: 0.0381 - val_loss: 0.0341\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 3s 464ms/step - loss: 0.0373 - val_loss: 0.0311\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 4s 518ms/step - loss: 0.0253 - val_loss: 0.0204\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 3s 441ms/step - loss: 0.0201 - val_loss: 0.0166\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 3s 502ms/step - loss: 0.0135 - val_loss: 0.0087\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 4s 560ms/step - loss: 0.0066 - val_loss: 0.0031\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 4s 522ms/step - loss: 0.0027 - val_loss: 0.0016\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 4s 490ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 4s 557ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 3s 451ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 4s 564ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 4s 509ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 3s 421ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 3s 473ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 3s 431ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 3s 442ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "16/16 [==============================] - 2s 56ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# Define the input layer\n",
        "input_signal = Input(shape=(4500, 1))\n",
        "\n",
        "# Build the convolutional layers\n",
        "x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(input_signal)\n",
        "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
        "x = Conv1D(8, kernel_size=3, activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling1D(pool_size=2, padding='same')(x)\n",
        "\n",
        "# Build the upsampling layers\n",
        "x = Conv1D(8, kernel_size=3, activation='relu', padding='same')(encoded)\n",
        "x = UpSampling1D(size=2)(x)\n",
        "x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(size=2)(x)\n",
        "decoded = Conv1D(1, kernel_size=3, activation='relu', padding='same')(x)\n",
        "\n",
        "# Compile the model\n",
        "conv2_autoencoder = Model(inputs=input_signal, outputs=decoded)\n",
        "conv2_autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "\n",
        "# Define checkpoint callback\n",
        "checkpoint_path = \"checkpoints/denoiser_model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "conv2_autoencoder.fit(X_train, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=64,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[checkpoint])\n",
        "\n",
        "                      \n",
        "# Predict using the trained (or best saved) model\n",
        "denoised_signal_conv2 = conv2_autoencoder.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ Load your trained model\n",
        "model = load_model(\"checkpoints/denoiser_model.h5\")\n",
        "\n",
        "# ✅ Prepare your input (reshape as needed)\n",
        "# Example: assume 'data[\"Amplitude_noise\"]' is the noisy signal\n",
        "X_noisy = data['Amplitude_noise'].values.reshape(1, -1, 1)  # shape: (1, time_steps, 1)\n",
        "\n",
        "# ✅ Predict denoised output\n",
        "denoised_signal_conv2 = model.predict(X_noisy)\n",
        "\n",
        "# ✅ Flatten for plotting\n",
        "denoised_signal_conv2 = denoised_signal_conv2.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "I0AQsXgFimiV",
        "outputId": "d6789a3d-68ea-448d-c181-77b870a5409d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Visualization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m time_steps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(data))\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(time_steps, data[\u001b[39m'\u001b[39m\u001b[39mAmplitude\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOriginal Amplitude\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Visualization\n",
        "time_steps = np.arange(len(data))\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.plot(time_steps, data['Amplitude'], label='Original Amplitude')\n",
        "plt.plot(time_steps, data['Amplitude_noise'], label='Noised Amplitude')\n",
        "plt.plot(time_steps, denoised_signal.flatten()[:len(data)], label='Conv1D Autoencoder Denoised')\n",
        "plt.plot(time_steps, denoised_signal_lstm.flatten()[:len(data)], label='LSTM Autoencoder Denoised')\n",
        "plt.plot(time_steps, denoised_signal_conv2.flatten()[:len(data)], label='Enhanced Conv1D Autoencoder Denoised')\n",
        "\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Signal Denoising Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
